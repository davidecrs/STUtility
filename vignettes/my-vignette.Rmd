--
title: "STUtility - A  Utility tool from the original Spatial Transcriptomics Research group"
date: ""
author: 
- Joseph BergenstrÃ¥hle, Royal Institute of Technology (KTH)
- Ludvig Larsson, Royal Institute of Technology (KTH)
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{STUtility vignette}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(STutility)

```


Introduction
============

STUtility is an Rpackage which includes various R-functions for interaction and analysis of Spatial Transcriptomics (ST) data. During the years of internal development of the ST method, the research group at SciLifeLab has used a vast array of R functions in their daily work. As the method is becoming widely adopted 


Pre-process and read in data
=============

STUtility provides two approached for reading in data and creating the S4 object. 

### Method 1

Info.table sheet to load in our samples togheter with meta data. 
The table looks like this:

```{r, echo=FALSE}

abs.path <- system.file("extdata", package = "STutility")

```

```{r}

infoTable <- read.table(paste(abs.path, "metaData.csv", sep="/"), sep=";", header=T)

head(infoTable)
```

The `samples` are the only mandatory column. However, if spotfiles and images are provided, the column headers of `spotfiles` and `imgs` also need to be named accordingly. 

With the info table as input, we create the S4 object which contains all the samples as well as meta data. 

```{r, echo=FALSE}
fix <- list.files(system.file("extdata/counts", package = "STutility"), full.names = T)
fixCounts <- fix[grep(fix, pattern = "[^_]MOB[1-9].tsv")]
fixSpotfiles <- fix[grep(fix, pattern = "alignment")]
fixImgs <- fix[grep(fix, pattern = ".jpg")]

infoTable[,1] <- fixCounts
infoTable[,5] <- fixSpotfiles
infoTable[,6] <- fixImgs

```

```{r}

cm <- prep.from.table(sampleTable=infoTable, 
                      transpose=T, 
                      topN=0, th.gene=0, th.spot=0, 
                      type="Seurat")

```

```{r change genes ids}

ensids <- read.table(file = list.files(system.file("extdata", package = "STutility"), full.names = T, pattern = "mouse_genes"), header = T, sep = "\t", stringsAsFactors = F)
rownames(ensids) <- ensids$gene_id
cm@assays$RNA@counts@Dimnames[[1]] <- ensids[cm@assays$RNA@counts@Dimnames[[1]], ]$gene_name
cm@assays$RNA@data@Dimnames[[1]] <- ensids[cm@assays$RNA@data@Dimnames[[1]], ]$gene_name
rownames(cm@assays$RNA@meta.features) <- ensids[rownames(cm@assays$RNA@meta.features), ]$gene_name
#rownames(cm@assays$RNA@scale.data) <- ensids[rownames(cm@assays$RNA@scale.data), ]$gene_name
```

With the Seurat object created, we can proceed with the regular Seurat workflow to scale data, find variable features and conduct dimensionallity reductions:

```{r}
library(Seurat)
# store mitochondrial percentage in object meta data
cm <- PercentageFeatureSet(cm, pattern = "^MT-", col.name = "percent.mt")
# run sctransform
cm <- SCTransform(cm, vars.to.regress = "percent.mt", verbose = FALSE)
# These are now standard steps in the Seurat workflow for visualization and clustering
cm <- RunPCA(cm, verbose = FALSE)
cm <- RunUMAP(cm, dims = 1:30, verbose = FALSE)

cm <- FindNeighbors(cm, dims = 1:30, verbose = FALSE)
cm <- FindClusters(cm, verbose = FALSE)

```

For other alternatives, see the Seurat vignettes at https://satijalab.org/seurat/ . Every output is saved into the Seurat object. Visualization can be performed in the usual manner:

```{r, fig.width = 10, fig.height = 12}

cm <- SetIdent(cm, value = "sample")
DimPlot(object = cm, dims = 1:2)

```

Or, we can use the prefix "ST", if instead we would like to visualize the output onto the spatial array:

```{r, fig.width = 10, fig.height = 3}

ST.DimPlot(object = cm, 
           reduction = "ica",
           dims = 1:3, 
           group.by = "sample", 
           delim = "x|_", 
           rev.cols = F,
           pt.size = 1,
           dark.theme = T, 
           ncol = 4, 
           grid.ncol = 1, 
           blend = T)

```



### 

```{r, fig.width = 10, fig.height = 3}

<<<<<<< HEAD
```

```{r}

Idents(se) <- "sample"
avg.exp <- AverageExpression(se, return.seurat = F, verbose=T, add.ident = "sample")
pairs(avg.exp$SCT)

=======
ST.FeaturePlot(object = cm, 
               features = c("Nrgn", "Penk", "Cck"), 
               group.by = "sample", 
               delim = "x|_", 
               center.zero = F, 
               rev.cols = T, 
               dark.theme = T,
               ncol = 4, 
               grid.ncol = 1, 
               blend = T)
>>>>>>> origin/master

```





## Method 2







## Spatial Expression Histology (SEH)


```{r, fig.width = 10, fig.height = 21}

#seh <- runSEH(cm, n.clust=10,
#              n.start=10, 
#              m.iter=10,
#              log.freq = T)
cm <- seh

<<<<<<< HEAD


#Test to add correlation gene-matrix to guide user to choose k...
# SAVE ALL THESE CHANGES TO A "SEH" BRANCH ! 


```

```{r}

ST.DimPlot(object = seh, 
=======
ST.DimPlot(object = cm, 
>>>>>>> origin/master
           reduction = "SEH",
           dims = 1:7, 
           group.by = "sample", 
           delim = "x|_", 
           palette = "viridis",
           rev.cols = F,
           pt.size = 1,
           dark.theme = T, 
           ncol = 4, 
           grid.ncol = 1, 
           center.zero = F)
```




```{r}


bigcov <- function(x, nblocks = 10, verbose = TRUE, ...)
{
library(ff, quietly = TRUE)
NCOL <- ncol(x)
 
## test if ncol(x) %% nblocks gives remainder 0
if (NCOL %% nblocks != 0) stop("Choose different 'nblocks' so that ncol(x) %% nblocks = 0!")
 
## preallocate square matrix of dimension
## ncol(x) in 'ff' single format
corMAT <- ff(vmode = "single", dim = c(NCOL, NCOL))
 
## split column numbers into 'nblocks' groups
SPLIT <- split(1:NCOL, rep(1:nblocks, each = NCOL/nblocks))
 
## create all unique combinations of blocks
COMBS <- expand.grid(1:length(SPLIT), 1:length(SPLIT))
COMBS <- t(apply(COMBS, 1, sort))
COMBS <- unique(COMBS)
 
## iterate through each block combination, calculate correlation matrix
## between blocks and store them in the preallocated matrix on both
## symmetric sides of the diagonal
for (i in 1:nrow(COMBS)) {
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COV <- cov(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COV
corMAT[G2, G1] <- t(COV)
COV <- NULL
}
 
gc()
return(corMAT)
}

library(superheat)
superheat(res)
```

